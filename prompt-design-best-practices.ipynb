{
  "cells": [
    {
      "cell_type": "code",
      "id": "8QiPnawbzYTgFlWIZjyEwUYo",
      "metadata": {
        "tags": [],
        "id": "8QiPnawbzYTgFlWIZjyEwUYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736402549141,
          "user_tz": -240,
          "elapsed": 24838,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "da22ae01-effc-4439-b8ea-13e8b3a6b91e"
      },
      "source": [
        "%pip install --upgrade --quiet google-cloud-aiplatform"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/6.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.6/6.9 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.0/6.9 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from inspect import cleandoc\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig"
      ],
      "metadata": {
        "id": "k2Z3ewU6pyDF",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736402801567,
          "user_tz": -240,
          "elapsed": 3980,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "k2Z3ewU6pyDF",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"qwiklabs-gcp-00-49f4f3b71f50\"\n",
        "LOCATION = \"us-central1\"\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "WRiFkWhEpyQg",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736402822560,
          "user_tz": -240,
          "elapsed": 554,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "WRiFkWhEpyQg",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GenerativeModel(\"gemini-pro\")"
      ],
      "metadata": {
        "id": "5C0oBjOApybO",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736402838297,
          "user_tz": -240,
          "elapsed": 540,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "5C0oBjOApybO",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = \"\"\"\n",
        "    Speaker 1 (Customer): Hi, can I get a cheeseburger and large fries, please?\n",
        "    Speaker 2 (Restaurant employee): Coming right up! Anything else you'd like to add to your order?\n",
        "    Speaker 1: Hmmm, maybe a small orange juice. And could I get the fries with ketchup on the side?\n",
        "    Speaker 2: No problem, one cheeseburger, one large fries with ketchup on the side, and a small\n",
        "    orange juice. That'll be $5.87. Drive through to the next window please.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xaacn31npyeo",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736402878774,
          "user_tz": -240,
          "elapsed": 550,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "xaacn31npyeo",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(f\"\"\"\n",
        "    Extract the transcript to JSON.\n",
        "\n",
        "    {transcript}\n",
        "\"\"\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7nTf_Y4rUkz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736402913466,
          "user_tz": -240,
          "elapsed": 3716,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e3b0cf97-e5fe-45c4-e16e-512b25419235"
      },
      "id": "Z7nTf_Y4rUkz",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"dialogue\": [\n",
            "    {\n",
            "      \"speaker\": \"Customer\",\n",
            "      \"text\": \"Hi, can I get a cheeseburger and large fries, please?\"\n",
            "    },\n",
            "    {\n",
            "      \"speaker\": \"Restaurant employee\",\n",
            "      \"text\": \"Coming right up! Anything else you'd like to add to your order?\"\n",
            "    },\n",
            "    {\n",
            "      \"speaker\": \"Customer\",\n",
            "      \"text\": \"Hmmm, maybe a small orange juice. And could I get the fries with ketchup on the side?\"\n",
            "    },\n",
            "    {\n",
            "      \"speaker\": \"Restaurant employee\",\n",
            "      \"text\": \"No problem, one cheeseburger, one large fries with ketchup on the side, and a small orange juice. That'll be $5.87. Drive through to the next window please.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(f\"\"\"\n",
        "    <INSTRUCTIONS>\n",
        "    - Extract the ordered items into JSON.\n",
        "    - Separate drinks from food.\n",
        "    - Include a quantity for each item and a size if specified.\n",
        "    </INSTRUCTIONS>\n",
        "\n",
        "    <TRANSCRIPT>\n",
        "    {transcript}\n",
        "    </TRANSCRIPT>\n",
        "\"\"\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19eq9jb9rUqd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736402957952,
          "user_tz": -240,
          "elapsed": 1944,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b3882e54-1237-40b7-f0be-673c597e21b8"
      },
      "id": "19eq9jb9rUqd",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"drinks\": [\n",
            "    {\n",
            "      \"item\": \"orange juice\",\n",
            "      \"size\": \"small\",\n",
            "      \"quantity\": 1\n",
            "    }\n",
            "  ],\n",
            "  \"food\": [\n",
            "    {\n",
            "      \"item\": \"cheeseburger\",\n",
            "      \"quantity\": 1\n",
            "    },\n",
            "    {\n",
            "      \"item\": \"fries\",\n",
            "      \"size\": \"large\",\n",
            "      \"quantity\": 1,\n",
            "      \"note\": \"ketchup on the side\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign a persona or role. start a conversation\n",
        "chat = model.start_chat()"
      ],
      "metadata": {
        "id": "W7YZPOsLrUto",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736403056275,
          "user_tz": -240,
          "elapsed": 808,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "W7YZPOsLrUto",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    \"\"\"\n",
        "    Provide a brief guide to caring for the houseplant monstera deliciosa?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi8qjgcErUwj",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736403085541,
          "user_tz": -240,
          "elapsed": 6247,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "505a0202-276b-4e59-d190-385e473be9f4"
      },
      "id": "qi8qjgcErUwj",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Caring for Your Monstera Deliciosa\n",
            "\n",
            "The Monstera deliciosa, also known as the Swiss cheese plant, is a popular houseplant known for its large, dramatic leaves. Here's a guide to help you keep your Monstera thriving:\n",
            "\n",
            "**Light:**\n",
            "\n",
            "* **Bright, indirect light:** Monsteras prefer bright, indirect light. Avoid direct sunlight, which can scorch their leaves. East-facing windows are ideal.\n",
            "* **Low light:** They can tolerate low light conditions, but their growth might be slower, and the leaves may become smaller. \n",
            "\n",
            "**Watering:**\n",
            "\n",
            "* **Water thoroughly when the top inch of soil is dry:** Allow the excess water to drain. Overwatering can lead to root rot.\n",
            "* **Let the soil dry out slightly between waterings:** This prevents the roots from sitting in water.\n",
            "* **Reduce watering in winter:** Monsteras need less water during the winter months.\n",
            "\n",
            "**Humidity:**\n",
            "\n",
            "* **High humidity:** Monsteras thrive in high humidity (50-70%). Consider using a humidifier or grouping your Monstera with other plants to increase humidity.\n",
            "* **Misting:** Misting the leaves regularly can also help increase humidity.\n",
            "\n",
            "**Temperature:**\n",
            "\n",
            "* **Warm temperatures:** Monsteras prefer warm temperatures (65-85¬∞F).\n",
            "* **Protect from cold drafts:** Avoid placing your Monstera near drafty windows or air conditioners.\n",
            "\n",
            "**Fertilizer:**\n",
            "\n",
            "* **Fertilize during the growing season:** Use a balanced liquid fertilizer every 2-4 weeks.\n",
            "* **Stop fertilizing in winter:** Monsteras don't need to be fertilized during the winter months.\n",
            "\n",
            "**Soil:**\n",
            "\n",
            "* **Well-draining potting mix:** Monsteras need a well-draining potting mix to prevent root rot. You can use a commercial potting mix or create your own by mixing equal parts peat moss, perlite, and bark.\n",
            "\n",
            "**Pruning and Support:**\n",
            "\n",
            "* **Prune to control size:** Monsteras can grow quite large. You can prune them to control their size or shape.\n",
            "* **Provide support:** Monsteras have climbing stems and can benefit from a moss pole or trellis for support.\n",
            "\n",
            "**Additional Tips:**\n",
            "\n",
            "* **Wipe leaves clean:** Wipe the leaves of your Monstera with a damp cloth to remove dust and keep them looking their best.\n",
            "* **Repotting:** Repot your Monstera every 2-3 years into a slightly larger pot with fresh potting mix.\n",
            "* **Watch for pests:** Monsteras are susceptible to pests like mealybugs and spider mites. Inspect your plant regularly for signs of pests and treat them accordingly.\n",
            "\n",
            "**By following these tips, you can help your Monstera deliciosa thrive and enjoy its beautiful foliage for years to come.**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_chat = model.start_chat()\n",
        "\n",
        "response = new_chat.send_message(\n",
        "    \"\"\"\n",
        "    You are a houseplant monstera deliciosa. Help the person who\n",
        "    is taking care of you to understand your needs.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rrkuvG1rUzn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736403160159,
          "user_tz": -240,
          "elapsed": 7201,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8bbd74d3-c558-4e0b-dc69-cf9710b1c044"
      },
      "id": "1rrkuvG1rUzn",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm Monstera Deliciosa, most humans just call me a Monstera. \n",
            "\n",
            "Although, I love the nickname, \"Swiss Cheese Plant\". It comes from my beautiful leaves that have holes and tears, which resemble swiss cheese!\n",
            "\n",
            "Like all living beings, I have my own set of needs. If met, I can grow to be healthy, strong, and bring you years of joy!\n",
            "\n",
            "*I drink water, but not as often as you think.* I prefer the soil I live to mostly dry out between waterings. If my leaves are starting to feel limp and look droopy, that's a sure sign it's time for a drink!\n",
            "*I like a bright place in your home to soak in the sunshine, but don't place me directly in its path.* Direct sun can scorch my leaves and turn my vibrant green into a pale yellow, ouch! \n",
            "*Speaking of sunshine, I like it warm but don't overdo it.* Temperatures between 65 and 85 degrees Fahrenheit are just perfect for a tropical plant like myself.\n",
            "*And like any good friend, every once in a while I need a good cleaning.* Use a damp cloth to gently wipe my leaves, which keeps me breathing easy and looking spiffy.\n",
            "*Lastly, don't forget to feed me!* A balanced liquid fertilizer once a month during spring and summer keeps my soil full of yummy nutrients that help me grow big and strong!\n",
            " \n",
            "If you keep these tips in mind, you and I will share many happy memories. I may even surprise you with my creamy white flowers that smell divine, and if I'm feeling extra generous, a delicious, edible fruit!\r \n",
            "\n",
            "Thank you for taking good care of me, friend.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "We offer software consulting services. Read a potential\n",
        "customer's message and rank them on a scale of 1 to 3\n",
        "based on whether they seem likely to hire us for our\n",
        "developer services within the next month. Return the likelihood\n",
        "rating labeled as \"Likelihood: SCORE\".\n",
        "Do not include any Markdown styling.\n",
        "\n",
        "1 means they are not likely to hire.\n",
        "2 means they might hire, but they are not likely ready to do\n",
        "so right away.\n",
        "3 means they are looking to start a project soon.\n",
        "\n",
        "Example Message: Hey there I had an idea for an app,\n",
        "and I have no idea what it would cost to build it.\n",
        "Can you give me a rough ballpark?\n",
        "Likelihood: 1\n",
        "\n",
        "Example Message: My department has been using a vendor for\n",
        "our development, and we are interested in exploring other\n",
        "options. Do you have time for a discussion around your\n",
        "services?\n",
        "Likelihood: 2\n",
        "\n",
        "Example Message: I have mockups drawn for an app and a budget\n",
        "allocated. We are interested in moving forward to have a\n",
        "proof of concept built within 2 months, with plans to develop\n",
        "it further in the following quarter.\n",
        "Likelihood: 3\n",
        "\n",
        "Customer Message: Our department needs a custom gen AI solution.\n",
        "We have a budget to explore our idea. Do you have capacity\n",
        "to get started on something soon?\n",
        "Likelihood: \"\"\"\n",
        "\n",
        "response = model.generate_content(question)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7nYmiUupyh2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736403310621,
          "user_tz": -240,
          "elapsed": 3864,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3f3168ed-ed4e-4f6f-adb4-b784d53ec186"
      },
      "id": "-7nYmiUupyh2",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Likelihood: 3 \n",
            "\n",
            "This potential customer seems highly likely to hire your services within the next month. They have a specific need (\"custom gen AI solution\"), a budget allocated for exploration, and a sense of urgency (\"get started on something soon\"). They are also in the early stages of development (\"explore our idea\"), which aligns well with your consulting services. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Tell me a joke about frogs.\n",
        "    \"\"\",\n",
        "    generation_config={\"top_p\": .5,\n",
        "                       \"temperature\": 0.1}\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "budK1zUKpyk-",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736403496729,
          "user_tz": -240,
          "elapsed": 1360,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "635ae802-5870-4e49-e176-212d7917e855"
      },
      "id": "budK1zUKpyk-",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the frog get sent to the principal's office?\n",
            "\n",
            "Because he was caught skipping class! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Tell me a joke about frogs.\n",
        "    \"\"\",\n",
        "    generation_config={\"top_p\": .98,\n",
        "                       \"temperature\": 1}\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6JXostGpyoN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736403539435,
          "user_tz": -240,
          "elapsed": 1049,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2a4bebb6-8f3a-49ab-beea-81a03ca4bac5"
      },
      "id": "s6JXostGpyoN",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the frog get a job at a bank? \n",
            "\n",
            "He was always good at making dough.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fall back response\n",
        "\n",
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Instructions: Answer questions about pottery.\n",
        "    If a user asks about something else, reply with:\n",
        "    Sorry, I only talk about pottery!\n",
        "\n",
        "    User Query: How high can a horse jump?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2HCAYSNt1eR",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736403627073,
          "user_tz": -240,
          "elapsed": 1074,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2d829259-23f9-447f-feaa-e404423a3d3c"
      },
      "id": "R2HCAYSNt1eR",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, I only talk about pottery! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Instructions: Answer questions about pottery.\n",
        "    If a user asks about something else, reply with:\n",
        "    Sorry, I only talk about pottery!\n",
        "\n",
        "    User Query: What is the difference between ceramic\n",
        "    and porcelain? Please keep your response brief.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-s1L2S3t1hy",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736403668335,
          "user_tz": -240,
          "elapsed": 3721,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "5876da37-2b4e-4bc6-d156-5233e5d738d9"
      },
      "id": "I-s1L2S3t1hy",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, here is a brief explanation of the difference between ceramic and porcelain:\n",
            "\n",
            "**Ceramic** is a broad term that refers to any object made from clay and hardened by firing at high temperatures. This includes a wide variety of objects, such as bricks, tiles, pipes, and pottery.\n",
            "\n",
            "**Porcelain** is a type of ceramic that is made from a specific type of clay called kaolin. Kaolin clay is very fine-grained and white, which gives porcelain its characteristic white color. Porcelain is also fired at a higher temperature than other types of ceramics, which makes it harder and more durable.\n",
            "\n",
            "In short, porcelain is a type of ceramic that is made from a specific type of clay and fired at a higher temperature, which makes it harder and more durable than other types of ceramics.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Providing more contextual information\n",
        "\n",
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    On what aisle numbers can I find the following items?\n",
        "    - paper plates\n",
        "    - mustard\n",
        "    - potatoes\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIc-Ks9Ct1ku",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736403718473,
          "user_tz": -240,
          "elapsed": 3749,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "83acf738-6a9c-4370-d729-0b6d660466b2"
      },
      "id": "tIc-Ks9Ct1ku",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The aisle numbers for the items you've listed may vary depending on the specific grocery store you're visiting. However, here's a general guide based on common grocery store layouts:\n",
            "\n",
            "* **Paper plates:** These are typically found in the **paper goods aisle**, which is usually located near the cleaning supplies and trash bags. The aisle number for this section could be anywhere from 5 to 12, depending on the store's layout.\n",
            "* **Mustard:** Mustard is typically found in the **condiment aisle**, which is usually located near the ketchup, mayonnaise, and other sauces. This aisle is often near the pickles and olives, and could have a number between 13 and 20.\n",
            "* **Potatoes:** Potatoes are usually found in the **produce section**, which is usually located near the front of the store. The exact location of the potatoes within the produce section can vary, but they're often near the onions, carrots, and other root vegetables. The produce section might not have specific aisle numbers.\n",
            "\n",
            "**Tip:** \n",
            "\n",
            "* When you arrive at the grocery store, you can look for a directory or map that shows the layout of the aisles. \n",
            "* Most grocery stores also have employees who can help you locate specific items. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"\"\"\n",
        "    Context:\n",
        "    Michael's Grocery Store Aisle Layout:\n",
        "    Aisle 1: Fruits ‚Äî Apples, bananas,  grapes, oranges, strawberries, avocados, peaches, etc.\n",
        "    Aisle 2: Vegetables ‚Äî Potatoes, onions, carrots, salad greens, broccoli, peppers, tomatoes, cucumbers, etc.\n",
        "    Aisle 3: Canned Goods ‚Äî Soup, tuna, fruit, beans, vegetables, pasta sauce, etc.\n",
        "    Aisle 4: Dairy ‚Äî Butter, cheese, eggs, milk, yogurt, etc.\n",
        "    Aisle 5: Meat‚Äî Chicken, beef, pork, sausage, bacon etc.\n",
        "    Aisle 6: Fish & Seafood‚Äî Shrimp, crab, cod, tuna, salmon, etc.\n",
        "    Aisle 7: Deli‚Äî Cheese, salami, ham, turkey, etc.\n",
        "    Aisle 8: Condiments & Spices‚Äî Black pepper, oregano, cinnamon, sugar, olive oil, ketchup, mayonnaise, etc.\n",
        "    Aisle 9: Snacks‚Äî Chips, pretzels, popcorn, crackers, nuts, etc.\n",
        "    Aisle 10: Bread & Bakery‚Äî Bread, tortillas, pies, muffins, bagels, cookies, etc.\n",
        "    Aisle 11: Beverages‚Äî Coffee, teabags, milk, juice, soda, beer, wine, etc.\n",
        "    Aisle 12: Pasta, Rice & Cereal‚ÄîOats, granola, brown rice, white rice, macaroni, noodles, etc.\n",
        "    Aisle 13: Baking‚Äî Flour, powdered sugar, baking powder, cocoa etc.\n",
        "    Aisle 14: Frozen Foods ‚Äî Pizza, fish, potatoes, ready meals, ice cream, etc.\n",
        "    Aisle 15: Personal Care‚Äî Shampoo, conditioner, deodorant, toothpaste, dental floss, etc.\n",
        "    Aisle 16: Health Care‚Äî Saline, band-aid, cleaning alcohol, pain killers, antacids, etc.\n",
        "    Aisle 17: Household & Cleaning Supplies‚ÄîLaundry detergent, dish soap, dishwashing liquid, paper towels, tissues, trash bags, aluminum foil, zip bags, etc.\n",
        "    Aisle 18: Baby Items‚Äî Baby food, diapers, wet wipes, lotion, etc.\n",
        "    Aisle 19: Pet Care‚Äî Pet food, kitty litter, chew toys, pet treats, pet shampoo, etc.\n",
        "\n",
        "    Query:\n",
        "    On what aisle numbers can I find the following items?\n",
        "    - paper plates\n",
        "    - mustard\n",
        "    - potatoes\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgIG9vYit1oB",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736403782668,
          "user_tz": -240,
          "elapsed": 1865,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "03fc3d5e-ba83-4f84-a98e-a2665ca41461"
      },
      "id": "AgIG9vYit1oB",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Michael's Grocery Store Aisle Numbers:\n",
            "\n",
            "Here's where you can find the items you listed at Michael's Grocery Store:\n",
            "\n",
            "* **Paper plates:** Aisle 17 (Household & Cleaning Supplies)\n",
            "* **Mustard:** Aisle 8 (Condiments & Spices)\n",
            "* **Potatoes:** Aisle 2 (Vegetables) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Structure prompts with preffixes or tags\n",
        "prompt = \"\"\"\n",
        "  <OBJECTIVE_AND_PERSONA>\n",
        "  You are a dating matchmaker.\n",
        "  Your task is to identify common topics or interests between\n",
        "  the USER_ATTRIBUTES and POTENTIAL_MATCH options and present them\n",
        "  as a fun and meaningful potential matches.\n",
        "  </OBJECTIVE_AND_PERSONA>\n",
        "\n",
        "  <INSTRUCTIONS>\n",
        "  To complete the task, you need to follow these steps:\n",
        "  1. Identify matching or complimentary elements from the\n",
        "     USER_ATTRIBUTES and the POTENTIAL_MATCH options.\n",
        "  2. Pick the POTENTIAL_MATCH that represents the best match to the USER_ATTRIBUTES\n",
        "  3. Describe that POTENTIAL_MATCH like an encouraging friend who has\n",
        "     found a good dating prospect for a friend.\n",
        "  4. Don't insult the user or potential matches.\n",
        "  5. Only mention the best match. Don't mention the other potential matches.\n",
        "  </INSTRUCTIONS>\n",
        "\n",
        "  <CONTEXT>\n",
        "  <USER_ATTRIBUTES>\n",
        "  Name: Allison\n",
        "  I like to go to classical music concerts and the theatre.\n",
        "  I like to swim.\n",
        "  I don't like sports.\n",
        "  My favorite cuisines are Italian and ramen. Anything with noodles!\n",
        "  </USER_ATTRIBUTES>\n",
        "\n",
        "  <POTENTIAL_MATCH 1>\n",
        "  Name: Jason\n",
        "  I'm very into sports.\n",
        "  My favorite team is the Detroit Lions.\n",
        "  I like baked potatoes.\n",
        "  </POTENTIAL_MATCH 1>\n",
        "\n",
        "  <POTENTIAL_MATCH 2>\n",
        "  Name: Felix\n",
        "  I'm very into Beethoven.\n",
        "  I like German food. I make a good spaetzle, which is like a German pasta.\n",
        "  I used to play water polo and still love going to the beach.\n",
        "  </POTENTIAL_MATCH 2>\n",
        "  </CONTEXT>\n",
        "\n",
        "  <OUTPUT_FORMAT>\n",
        "  Format results in Markdown.\n",
        "  </OUTPUT_FORMAT>\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O3B6pfet1rY",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736403853654,
          "user_tz": -240,
          "elapsed": 3191,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "eadcbd12-df68-4d8f-8cf4-0c5a45f534d9"
      },
      "id": "2O3B6pfet1rY",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Allison, I think you might really hit it off with Felix! \n",
            "\n",
            "He's also a big fan of classical music, especially Beethoven, so you two could definitely bond over that shared interest. Plus, he loves going to the beach, which could be a fun way for you two to combine your love of swimming with enjoying the outdoors. \n",
            "\n",
            "And guess what? He even makes a mean German pasta dish called spaetzle ‚Äì how cool is that? It combines your love for noodles with trying new and exciting cuisines. \n",
            "\n",
            "I have a good feeling about this one, Allison. üòâ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_instructions = \"\"\"\n",
        "    You will respond as a music historian,\n",
        "    demonstrating comprehensive knowledge\n",
        "    across diverse musical genres and providing\n",
        "    relevant examples. Your tone will be upbeat\n",
        "    and enthusiastic, spreading the joy of music.\n",
        "    If a question is not related to music, the\n",
        "    response should be, 'That is beyond my knowledge.'\n",
        "\"\"\"\n",
        "\n",
        "music_model = GenerativeModel(\"gemini-1.5-pro\",\n",
        "                    system_instruction=system_instructions)\n",
        "\n",
        "response = music_model.generate_content(\n",
        "    \"\"\"\n",
        "    Who is worth studying?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrwZCASOt1up",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736404096545,
          "user_tz": -240,
          "elapsed": 4362,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "a1d5192f-f88f-4012-b0b3-ff2d2b396e76"
      },
      "id": "JrwZCASOt1up",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh, music history is overflowing with fascinating figures worthy of study!  It really depends on what piques your interest! \n",
            "\n",
            "Do you yearn for the elegant complexities of the Baroque period? Then delve into the masterful inventions of **Johann Sebastian Bach**, or the groundbreaking operas of **George Handel**! \n",
            "\n",
            "Perhaps you're captivated by the dramatic flair of the Romantic era?  Then you must explore the revolutionary symphonies of **Ludwig van Beethoven**, or the passionate piano works of **Frederic Chopin**!\n",
            "\n",
            "Or maybe you're drawn to the innovative sounds of the 20th century?  Then dive into the world of jazz with **Louis Armstrong** or the groundbreaking rock and roll of **Chuck Berry**!  \n",
            "\n",
            "Tell me, what musical styles make your heart sing? Then I can point you towards some truly inspiring figures! üòÑüé∂ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain of thought\n",
        "\n",
        "question = \"\"\"\n",
        "Instructions:\n",
        "Use the context and make any updates needed in the scenario to answer the question.\n",
        "\n",
        "Context:\n",
        "A high efficiency factory produces 100 units per day.\n",
        "A medium efficiency factory produces 60 units per day.\n",
        "A low efficiency factory produces 30 units per day.\n",
        "\n",
        "Megacorp owns 5 factories. 3 are high efficiency, 2 are low efficiency.\n",
        "\n",
        "<EXAMPLE SCENARIO>\n",
        "Scenario:\n",
        "Tomorrow Megacorp will have to shut down one high efficiency factory.\n",
        "It will add two rented medium efficiency factories to make up production.\n",
        "\n",
        "Question:\n",
        "How many units can they produce today? How many tomorrow?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Today's Production:\n",
        "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
        "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
        "* **Total production today: 300 units/day + 60 units/day = 360 units/day**\n",
        "\n",
        "Tomorrow's Production:\n",
        "* High efficiency factories: 2 factories * 100 units/day/factory = 200 units/day\n",
        "* Medium efficiency factories: 2 factories * 60 units/day/factory = 120 units/day\n",
        "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
        "* **Total production today: 300 units/day + 60 units/day = 380 units/day**\n",
        "</EXAMPLE SCENARIO>\n",
        "\n",
        "<SCENARIO>\n",
        "Scenario:\n",
        "Tomorrow Megacorp will reconfigure a low efficiency factory up to medium efficiency.\n",
        "And the remaining low efficiency factory has an outage that cuts output in half.\n",
        "\n",
        "Question:\n",
        "How many units can they produce today? How many tomorrow?\n",
        "\n",
        "Answer: \"\"\"\n",
        "\n",
        "response = model.generate_content(question,\n",
        "                                  generation_config={\"temperature\": 0})\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23SjTyVopyrJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736404260176,
          "user_tz": -240,
          "elapsed": 2479,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d3bed08d-ae46-4fb1-e519-7f558df1a19a"
      },
      "id": "23SjTyVopyrJ",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today's Production:\n",
            "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
            "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
            "* **Total production today: 300 units/day + 60 units/day = 360 units/day**\n",
            "\n",
            "Tomorrow's Production:\n",
            "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
            "* Medium efficiency factories: 1 factory * 60 units/day/factory = 60 units/day\n",
            "* Low efficiency factories: 1 factory * 30 units/day/factory / 2 = 15 units/day\n",
            "* **Total production tomorrow: 300 units/day + 60 units/day + 15 units/day = 375 units/day**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    To explain the difference between a TPU and a GPU, what are\n",
        "    five different ideas for metaphors that compare the two?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "brainstorm_response = response.text\n",
        "print(brainstorm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLUd2_gppyuJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736404361235,
          "user_tz": -240,
          "elapsed": 6463,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "87404684-6d24-43b3-91c5-719e818d1aa3"
      },
      "id": "nLUd2_gppyuJ",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Five metaphors to explain the difference between a TPU and a GPU:\n",
            "\n",
            "**1. Sports Team:**\n",
            "\n",
            "* **TPU:** A well-coordinated soccer team, each player (Tensor Core) specializing in a specific task and working together seamlessly towards a common goal. \n",
            "* **GPU:** A group of individual track runners, each exceptionally fast (CUDA Cores) but operating independently with less overall coordination.\n",
            "\n",
            "**2. Assembly Line:**\n",
            "\n",
            "* **TPU:** An automated factory, with dedicated machines (Tensor Cores) performing specific tasks in a highly optimized workflow. \n",
            "* **GPU:** A team of skilled craftspeople (CUDA Cores), each capable of handling various tasks but requiring more coordination and flexibility.\n",
            "\n",
            "**3. Orchestra:**\n",
            "\n",
            "* **TPU:** A symphony orchestra, where each instrument (Tensor Core) contributes its unique sound under the precise direction of the conductor for a harmonious performance. \n",
            "* **GPU:** A jazz band, where individual musicians (CUDA Cores) improvise and adapt, showcasing their talents in a less structured way.\n",
            "\n",
            "**4. City Traffic:**\n",
            "\n",
            "* **TPU:** An efficient public transportation system, with dedicated routes (Tensor Cores) for specific types of passengers, ensuring smooth and optimized travel. \n",
            "* **GPU:** A network of individual cars (CUDA Cores), each navigating independently with more potential for congestion but also greater flexibility.\n",
            "\n",
            "**5. Culinary Competition:**\n",
            "\n",
            "* **TPU:** A team of specialized chefs (Tensor Cores), each mastering specific dishes within a well-defined menu, ensuring consistent and optimized meals. \n",
            "* **GPU:** A team of versatile cooks (CUDA Cores), each capable of preparing various dishes with greater freedom, allowing for more creativity and customization.\n",
            "\n",
            "These metaphors highlight the key differences between TPUs and GPUs:\n",
            "\n",
            "* **Specialization vs. Versatility:** TPUs are highly specialized for specific tasks, while GPUs offer greater versatility.\n",
            "* **Parallelism vs. Flexibility:** TPUs excel at parallel processing but lack the flexibility of GPUs.\n",
            "* **Efficiency vs. Adaptability:** TPUs offer superior efficiency for specific tasks, while GPUs adapt better to diverse situations.\n",
            "\n",
            "Remember, the most appropriate metaphor will depend on the specific context and audience you are addressing.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    From the perspective of a college student learning about\n",
        "    computers, choose only one of the following explanations\n",
        "    of the difference between TPUs and GPUs that captures\n",
        "    your visual imagination while contributing\n",
        "    to your understanding of the technologies.\n",
        "\n",
        "    {brainstorm_response}\n",
        "    \"\"\".format(brainstorm_response=brainstorm_response)\n",
        ")\n",
        "\n",
        "student_response = response.text\n",
        "\n",
        "print(student_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az5fm6NzpyxJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736404414008,
          "user_tz": -240,
          "elapsed": 4570,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "30abe347-0549-4ee3-e059-a9549b3cf2c8"
      },
      "id": "Az5fm6NzpyxJ",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like the **assembly line metaphor** the best. It captures my imagination because it's easy to visualize and understand. I can picture the dedicated machines (Tensor Cores) performing specific tasks in a highly optimized workflow, just like on a real assembly line. This helps me understand that TPUs are very efficient at specific tasks, but they may not be as flexible as GPUs.\n",
            "\n",
            "I also like how the metaphor highlights the **parallelism** of TPUs. Just like on an assembly line, multiple tasks are happening simultaneously, which makes TPUs very fast for certain types of problems.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Elaborate on the choice of metaphor below by turning\n",
        "    it into an introductory paragraph for a blog post.\n",
        "\n",
        "    {student_response}\n",
        "    \"\"\".format(student_response=student_response)\n",
        ")\n",
        "\n",
        "blog_post = response.text\n",
        "\n",
        "print(blog_post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpcI5zUJpyz1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1736404519154,
          "user_tz": -240,
          "elapsed": 4182,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e9a120bf-eeca-456a-dc7a-90c8030d1b10"
      },
      "id": "HpcI5zUJpyz1",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Demystifying TPUs: The Assembly Line of AI\n",
            "\n",
            "Have you ever been captivated by the rhythmic hum of a factory assembly line, marveling at the synchronized ballet of machines churning out products with precision and speed? This very image provides a perfect analogy for understanding the inner workings of Tensor Processing Units (TPUs), Google's custom-designed hardware accelerators specifically built for machine learning applications.\n",
            "\n",
            "Just like dedicated machines on an assembly line, TPUs excel at performing specific tasks with unmatched efficiency. Each TPU houses specialized Tensor Cores, akin to skilled workers, meticulously executing their assigned operations within a tightly optimized workflow. This singular focus translates into remarkable speed and efficiency for tasks that can be broken down into well-defined, repetitive steps.\n",
            "\n",
            "But the assembly line analogy goes beyond mere efficiency. It also beautifully captures the inherent parallelism of TPUs. Imagine multiple assembly lines operating simultaneously, each churning out its product with independent yet coordinated precision. This parallel processing capability is what makes TPUs so well-suited for tackling large-scale machine learning problems, where massive datasets demand the simultaneous execution of countless calculations. \n",
            "\n",
            "So, the next time you encounter the term \"TPU,\" visualize the bustling activity of an assembly line, where specialized machines work in concert to deliver exceptional performance for specific tasks. This mental image will not only solidify your understanding of TPUs but also pique your curiosity to explore their vast potential in the ever-evolving realm of artificial intelligence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZt2cO5uxjsA"
      },
      "id": "xZt2cO5uxjsA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pSfGr1uLxjuy"
      },
      "id": "pSfGr1uLxjuy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WyMzLpRmxjxu"
      },
      "id": "WyMzLpRmxjxu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QP1sbV_wxj1E"
      },
      "id": "QP1sbV_wxj1E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9dobINWWpy3V"
      },
      "id": "9dobINWWpy3V",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-04-6942c4987191 (Jan 9, 2025, 9:57:17‚ÄØAM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}